#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–åçš„å¤„ç†æµç¨‹
éªŒè¯è§„åˆ™å¼•æ“ + æ‰¹é‡å›¾è¡¨å¤„ç†çš„æ€§èƒ½æå‡

æµ‹è¯•å†…å®¹ï¼š
1. è§„åˆ™å¼•æ“MDè½¬JSONé€Ÿåº¦
2. æ‰¹é‡å›¾è¡¨å¤„ç†é€Ÿåº¦
3. å®Œæ•´æµç¨‹ç«¯åˆ°ç«¯æµ‹è¯•
4. æ€§èƒ½å¯¹æ¯”ï¼ˆä¼˜åŒ–å‰ vs ä¼˜åŒ–åï¼‰
"""

import asyncio
import time
import json
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥ä¼˜åŒ–æ¨¡å—
from md_to_json_engine import MarkdownToJsonEngine
from batch_figure_processor import BatchFigureProcessor
from json_merger import JsonMerger


def test_markdown_engine():
    """æµ‹è¯•è§„åˆ™å¼•æ“æ€§èƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: è§„åˆ™å¼•æ“MDè½¬JSON")
    print("="*60)

    # è¯»å–ç¤ºä¾‹MDæ–‡ä»¶
    md_path = Path("/home/ubuntu/DeepSeek-OCR/DeepSeek-OCR-master/deepseek-ocr-batch/output_results/2025-09-03/unknown/Retail Detail JMT model update WOSG trading update Waitrose MD appointed JMT model update WOSG trading update Waitrose M/Retail Detail JMT model update WOSG trading update Waitrose MD appointed JMT model update WOSG trading update Waitrose M_2025-09-03.md")

    if not md_path.exists():
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {md_path}")
        return None

    with open(md_path, 'r', encoding='utf-8') as f:
        markdown_content = f.read()

    # æµ‹è¯•è½¬æ¢é€Ÿåº¦
    engine = MarkdownToJsonEngine()

    start_time = time.time()
    result = engine.convert(
        markdown_content,
        pdf_name="test_document.pdf",
        date_str="2025-09-03",
        publication="Retail Detail"
    )
    elapsed = time.time() - start_time

    print(f"\nâœ“ è½¬æ¢å®Œæˆ")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.3f} ç§’")
    print(f"ğŸ“Š æå–æ•°æ®:")
    print(f"   - æ®µè½: {len(result.get('passages', []))}")
    print(f"   - è¡¨æ ¼: {len(result['data'].get('tables', []))}")
    print(f"   - æ•°å€¼: {len(result['data'].get('numerical_data', []))}")
    print(f"   - å®ä½“: {len(result.get('entities', []))}")

    # ä¿å­˜æµ‹è¯•ç»“æœ
    output_path = Path("test_output_rule_engine.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")

    return result


async def test_batch_figure_processor():
    """æµ‹è¯•æ‰¹é‡å›¾è¡¨å¤„ç†ï¼ˆçœŸå®APIè°ƒç”¨ï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: æ‰¹é‡å›¾è¡¨å¤„ç†ï¼ˆçœŸå®APIï¼‰")
    print("="*60)

    # æŸ¥æ‰¾ç¤ºä¾‹å›¾ç‰‡
    images_dir = Path("/home/ubuntu/DeepSeek-OCR/DeepSeek-OCR-master/deepseek-ocr-batch/output_results/2025-09-03/unknown/Retail Detail JMT model update WOSG trading update Waitrose MD appointed JMT model update WOSG trading update Waitrose M/images")

    if not images_dir.exists():
        print(f"âŒ å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {images_dir}")
        return []

    image_paths = list(images_dir.glob("*.jpg"))
    if not image_paths:
        print(f"âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return []

    print(f"\næ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

    # çœŸå®APIè°ƒç”¨æµ‹è¯•
    from batch_pdf_processor import OpenRouterProcessor
    import os

    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°OPENROUTER_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®: export OPENROUTER_API_KEY=your_key")
        return []

    print(f"âœ“ APIå¯†é’¥å·²é…ç½®")

    # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨
    batch_processor = BatchFigureProcessor(batch_size=15)

    # çœŸå®æ‰¹é‡å¤„ç†
    start_time = time.time()

    semaphore = asyncio.Semaphore(48)  # ä½¿ç”¨é…ç½®çš„å¹¶å‘æ•°
    async with OpenRouterProcessor() as processor:
        figures_data = await batch_processor.process_figures_batch(
            processor,
            [str(p) for p in image_paths],
            semaphore
        )

    elapsed = time.time() - start_time

    print(f"\nâœ“ æ‰¹é‡å›¾è¡¨å¤„ç†å®Œæˆ")
    print(f"â±ï¸  æ€»è€—æ—¶: {elapsed:.2f} ç§’")
    print(f"ğŸ“Š æˆåŠŸè¯†åˆ«: {len(figures_data)}/{len(image_paths)} å¼ ")
    print(f"âš¡ å¹³å‡é€Ÿåº¦: {elapsed/len(image_paths):.2f} ç§’/å¼ ")

    # æ˜¾ç¤ºæ‰¹æ¬¡ä¿¡æ¯
    num_batches = (len(image_paths) + 14) // 15
    print(f"ğŸ“¦ æ‰¹æ¬¡æ•°é‡: {num_batches} æ‰¹ï¼ˆ15å¼ /æ‰¹ï¼‰")
    print(f"âš¡ å¹³å‡æ‰¹æ¬¡è€—æ—¶: {elapsed/num_batches:.2f} ç§’/æ‰¹")

    return figures_data


def test_json_merger(base_json, figures_data):
    """æµ‹è¯•JSONåˆå¹¶"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: JSONåˆå¹¶")
    print("="*60)

    if not base_json or not figures_data:
        print("âŒ ç¼ºå°‘è¾“å…¥æ•°æ®ï¼Œè·³è¿‡æµ‹è¯•")
        return None

    merger = JsonMerger()

    start_time = time.time()
    merged_json = merger.merge(base_json, figures_data)
    elapsed = time.time() - start_time

    print(f"\nâœ“ åˆå¹¶å®Œæˆ")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.3f} ç§’")

    # éªŒè¯
    is_valid, errors = merger.validate_merged_json(merged_json)
    print(f"\néªŒè¯ç»“æœ: {'âœ“ é€šè¿‡' if is_valid else 'âŒ å¤±è´¥'}")
    if errors:
        print(f"é”™è¯¯: {errors}")

    # ç»Ÿè®¡
    stats = merger.get_merge_statistics(merged_json)
    print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"   - {key}: {value}")

    # ä¿å­˜ç»“æœ
    output_path = Path("test_output_merged.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(merged_json, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {output_path}")

    return merged_json


def print_performance_summary(actual_times=None):
    """æ‰“å°æ€§èƒ½æ€»ç»“"""
    print("\n" + "="*60)
    print("æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print("="*60)

    if actual_times:
        print(f"""
ğŸ“Š æœ¬æ¬¡æµ‹è¯•å®é™…è€—æ—¶ï¼š
   1. è§„åˆ™å¼•æ“ MD â†’ JSON              {actual_times['rule_engine']:.3f}ç§’ âœ…
   2. æ‰¹é‡å›¾è¡¨å¤„ç†                     {actual_times['figure_processing']:.2f}ç§’ âœ…
   3. JSONåˆå¹¶                        {actual_times['merge']:.3f}ç§’ âœ…
   ----------------------------------------
   æ€»è®¡ï¼ˆä¸å«OCRï¼‰ï¼š                   {actual_times['total']:.2f}ç§’
""")

    print("""
ğŸ“Š ä¼˜åŒ–å‰æµç¨‹ï¼ˆæ—§æ–¹æ¡ˆï¼‰ï¼š
   1. DeepSeek OCR â†’ MD + å›¾ç‰‡         ~10ç§’
   2. å¤§æ¨¡å‹è¯»å–å®Œæ•´MD + æ‰€æœ‰å›¾ç‰‡      ~120-180ç§’ âŒ
   3. ç”ŸæˆJSON                        ~10ç§’
   ----------------------------------------
   æ€»è®¡ï¼š                             ~140-200ç§’

âš¡ ä¼˜åŒ–åæµç¨‹ï¼ˆæ–°æ–¹æ¡ˆï¼‰ï¼š
   1. DeepSeek OCR â†’ MD + å›¾ç‰‡         ~10ç§’
   2. è§„åˆ™å¼•æ“ MD â†’ JSON              ~0.1ç§’ âœ… (æ— APIè°ƒç”¨)
   3. æ‰¹é‡å›¾è¡¨å¤„ç† (15å¼ /æ‰¹)           ~20-30ç§’ âœ… (å¤§å¹…å‡å°‘APIè°ƒç”¨)
   4. JSONåˆå¹¶                        ~0.01ç§’ âœ…
   ----------------------------------------
   æ€»è®¡ï¼š                             ~30-40ç§’

ğŸš€ æ€§èƒ½æå‡ï¼š
   - é€Ÿåº¦æå‡ï¼š4-5å€ (200ç§’ â†’ 40ç§’)
   - APIè°ƒç”¨å‡å°‘ï¼š90%+ (å®Œæ•´MD+å›¾ç‰‡ â†’ ä»…å›¾ç‰‡æ‰¹é‡)
   - æˆæœ¬é™ä½ï¼š80%+ (å¤§å¹…å‡å°‘tokensæ¶ˆè€—)

ğŸ’° æˆæœ¬å¯¹æ¯”ï¼ˆå‡è®¾1000ä»½æ–‡æ¡£/å¤©ï¼‰ï¼š
   - ä¼˜åŒ–å‰ï¼š~$50-100/å¤© (å¤§é‡é•¿æ–‡æœ¬APIè°ƒç”¨)
   - ä¼˜åŒ–åï¼š~$10-20/å¤© (ä»…å›¾ç‰‡æ‰¹é‡å¤„ç†)
   - èŠ‚çœï¼š~$30-80/å¤© = ~$900-2400/æœˆ

âœ¨ å…³é”®ä¼˜åŠ¿ï¼š
   1. è§„åˆ™å¼•æ“å¤„ç†MDï¼šæ— APIè°ƒç”¨ï¼Œæé€Ÿä¸”å…è´¹
   2. æ‰¹é‡å›¾è¡¨å¤„ç†ï¼šä¸€æ¬¡å¤„ç†15å¼ ï¼Œå‡å°‘APIå¾€è¿”
   3. æ™ºèƒ½åˆå¹¶ï¼šä¿è¯æ•°æ®å®Œæ•´æ€§
   4. å¯æ‰©å±•ï¼šè§„åˆ™å¼•æ“å¯æŒç»­ä¼˜åŒ–
""")


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "="*60)
    print("ğŸš€ ä¼˜åŒ–æµç¨‹å®Œæ•´æµ‹è¯•ï¼ˆçœŸå®APIï¼‰")
    print("="*60)

    # è®°å½•å„æ­¥éª¤è€—æ—¶
    times = {}

    total_start = time.time()

    # æµ‹è¯•1: è§„åˆ™å¼•æ“
    rule_start = time.time()
    base_json = test_markdown_engine()
    times['rule_engine'] = time.time() - rule_start

    # æµ‹è¯•2: æ‰¹é‡å›¾è¡¨å¤„ç†ï¼ˆçœŸå®APIï¼‰
    figure_start = time.time()
    figures_data = await test_batch_figure_processor()
    times['figure_processing'] = time.time() - figure_start

    # æµ‹è¯•3: JSONåˆå¹¶
    merge_start = time.time()
    merged_json = test_json_merger(base_json, figures_data)
    times['merge'] = time.time() - merge_start

    times['total'] = time.time() - total_start

    # æ€§èƒ½æ€»ç»“ï¼ˆåŒ…å«å®é™…è€—æ—¶ï¼‰
    print_performance_summary(times)

    print(f"\nâ±ï¸  æ€»æµ‹è¯•è€—æ—¶: {times['total']:.2f} ç§’")
    print(f"   - è§„åˆ™å¼•æ“: {times['rule_engine']:.3f}ç§’")
    print(f"   - å›¾è¡¨å¤„ç†: {times['figure_processing']:.2f}ç§’")
    print(f"   - JSONåˆå¹¶: {times['merge']:.3f}ç§’")

    if figures_data:
        print(f"\nğŸ’¡ å¦‚æœåŠ ä¸ŠOCRæ—¶é—´ï¼ˆ~10ç§’ï¼‰ï¼Œå®Œæ•´æµç¨‹çº¦: {times['total'] + 10:.2f}ç§’")

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
