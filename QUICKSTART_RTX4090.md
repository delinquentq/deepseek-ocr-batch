# RTX 4090 å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¯åŠ¨

æœ¬æŒ‡å—å¸®åŠ©ä½ åœ¨ RTX 4090 48G æ˜¾å¡ä¸Šå¿«é€Ÿå¯åŠ¨ DeepSeek OCR æ‰¹é‡å¤„ç†ç³»ç»Ÿã€‚

---

## âœ… å‰ç½®æ£€æŸ¥

### 1. ç¡¬ä»¶è¦æ±‚
```bash
# æ£€æŸ¥GPU
nvidia-smi

# åº”è¯¥çœ‹åˆ°ï¼š
# - GPU: NVIDIA GeForce RTX 4090
# - Memory: 48GB
```

### 2. è½¯ä»¶è¦æ±‚
- Python 3.10+
- CUDA 11.8
- Conda (æ¨è)

---

## ğŸ“¦ å®‰è£…æ­¥éª¤

### æ­¥éª¤ 1: åˆ›å»ºç¯å¢ƒ

```bash
# åˆ›å»º conda ç¯å¢ƒ
conda create -n deepseek-ocr python=3.10 -y
conda activate deepseek-ocr
```

### æ­¥éª¤ 2: å®‰è£… PyTorch

```bash
# å®‰è£… PyTorch (CUDA 11.8)
pip install torch==2.6.0 torchvision==0.21.0 --index-url https://download.pytorch.org/whl/cu118
```

### æ­¥éª¤ 3: å®‰è£…é¡¹ç›®ä¾èµ–

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /path/to/deepseek-ocr-batch

# å®‰è£…ä¾èµ–
pip install -r requirements_batch.txt
```

### æ­¥éª¤ 4: é…ç½®ç¯å¢ƒå˜é‡

```bash
# åˆ›å»º .env æ–‡ä»¶
cat > .env << EOF
OPENROUTER_API_KEY=your_api_key_here
DEEPSEEK_OCR_MODEL_PATH=deepseek-ai/DeepSeek-OCR
CUDA_VISIBLE_DEVICES=0
VLLM_USE_V1=0
EOF

# æˆ–è€…ç›´æ¥å¯¼å‡º
export OPENROUTER_API_KEY=your_api_key_here
```

**è·å– OpenRouter API Key:**
1. è®¿é—® https://openrouter.ai/
2. æ³¨å†Œè´¦å·
3. åœ¨ Keys é¡µé¢åˆ›å»º API Key

---

## ğŸ§ª æµ‹è¯•ç³»ç»Ÿ

```bash
# è¿è¡Œç³»ç»Ÿæµ‹è¯•
python test_batch_system.py
```

**é¢„æœŸè¾“å‡ºï¼š**
```
ğŸ”¬ ç¯å¢ƒæµ‹è¯•...
âœ… ç¯å¢ƒæµ‹è¯•: é€šè¿‡

ğŸ”¬ é…ç½®éªŒè¯...
âœ… é…ç½®éªŒè¯: é€šè¿‡

ğŸ”¬ JSON SchemaéªŒè¯...
âœ… JSON SchemaéªŒè¯: é€šè¿‡

ğŸ”¬ GPUæ˜¾å­˜æµ‹è¯•...
âœ… GPUæ˜¾å­˜æµ‹è¯•: é€šè¿‡
  - å¯ç”¨æ˜¾å­˜: 48GB
  - æ¨èé…ç½®: BATCH_SIZE=12, MAX_CONCURRENCY=16
```

---

## ğŸ“„ å¤„ç†ç¬¬ä¸€ä¸ªPDF

### 1. å‡†å¤‡PDFæ–‡ä»¶

```bash
# åˆ›å»ºè¾“å…¥ç›®å½•
mkdir -p input_pdfs

# å¤åˆ¶PDFæ–‡ä»¶åˆ°è¾“å…¥ç›®å½•
cp /path/to/your/document.pdf input_pdfs/
```

### 2. è¿è¡Œå¤„ç†

```bash
# å¤„ç†æ‰€æœ‰PDF
python run_batch_processor.py

# æˆ–è€…å¤„ç†æŒ‡å®šæ–‡ä»¶
python run_batch_processor.py -f document.pdf

# è·³è¿‡ç¡®è®¤æç¤º
python run_batch_processor.py -y
```

### 3. æŸ¥çœ‹ç»“æœ

```bash
# OCRç»“æœï¼ˆMarkdown + å›¾åƒï¼‰
ls -lh output_results/document/

# JSONæŠ¥å‘Š
ls -lh output_report/document/

# æŸ¥çœ‹JSONå†…å®¹
cat output_report/document/document.json | jq .
```

---

## ğŸ“Š é¢„æœŸæ€§èƒ½

### RTX 4090 48G æ€§èƒ½æŒ‡æ ‡

| æ–‡æ¡£å¤§å° | å¤„ç†æ—¶é—´ | æ˜¾å­˜ä½¿ç”¨ |
|---------|---------|---------|
| å°æ–‡æ¡£ (5-10é¡µ) | 40-60ç§’ | 38-40GB |
| ä¸­æ–‡æ¡£ (20-30é¡µ) | 90-150ç§’ | 40-42GB |
| å¤§æ–‡æ¡£ (50+é¡µ) | 4-6åˆ†é’Ÿ | 42-43GB |

### å®æ—¶ç›‘æ§

```bash
# ç»ˆç«¯1: ç›‘æ§GPU
watch -n 1 nvidia-smi

# ç»ˆç«¯2: ç›‘æ§æ—¥å¿—
tail -f logs/batch_processor.log

# ç»ˆç«¯3: ç›‘æ§ç³»ç»Ÿèµ„æº
htop
```

---

## ğŸ¯ ä¼˜åŒ–é…ç½®

### å½“å‰é…ç½®ï¼ˆæé€Ÿæ¨¡å¼ï¼‰

æ–‡ä»¶ï¼š`config_batch.py`

```python
# RTX 4090 48G æé€Ÿé…ç½®
GPU_MEMORY_UTILIZATION = 0.90  # 90% æ˜¾å­˜åˆ©ç”¨ç‡
MAX_CONCURRENCY = 16           # 16 å¹¶å‘è¯·æ±‚
BATCH_SIZE = 12                # æ¯æ‰¹12é¡µ
NUM_WORKERS = 24               # 24 é¢„å¤„ç†çº¿ç¨‹
MAX_CONCURRENT_PDFS = 6        # 6 å¹¶å‘PDF
MAX_CONCURRENT_API_CALLS = 12  # 12 å¹¶å‘API
```

### å¦‚æœé‡åˆ°é—®é¢˜

**æ˜¾å­˜ä¸è¶³ (OOM):**
```python
# é™ä½é…ç½®
config.hardware.BATCH_SIZE = 8
config.hardware.MAX_CONCURRENCY = 12
config.hardware.GPU_MEMORY_UTILIZATION = 0.85
```

**APIé™æµ:**
```python
# é™ä½APIå¹¶å‘
config.processing.MAX_CONCURRENT_API_CALLS = 8
config.api.RETRY_DELAY_BASE = 2
```

---

## ğŸ“ è¾“å‡ºç›®å½•ç»“æ„

```
é¡¹ç›®æ ¹ç›®å½•/
â”œâ”€â”€ input_pdfs/              # è¾“å…¥PDF
â”‚   â””â”€â”€ document.pdf
â”‚
â”œâ”€â”€ output_results/          # OCRç»“æœï¼ˆMD + å›¾åƒï¼‰
â”‚   â””â”€â”€ document/
â”‚       â”œâ”€â”€ document.md
â”‚       â””â”€â”€ images/
â”‚           â”œâ”€â”€ 0_0.jpg
â”‚           â””â”€â”€ 0_1.jpg
â”‚
â”œâ”€â”€ output_report/           # JSONæŠ¥å‘Šï¼ˆæ–°å¢ï¼‰
â”‚   â””â”€â”€ document/
â”‚       â”œâ”€â”€ document.json            # Schemaæ ¼å¼JSON
â”‚       â””â”€â”€ document_template.json   # æ¨¡æ¿æ ¼å¼JSON
â”‚
â””â”€â”€ logs/                    # æ—¥å¿—
    â””â”€â”€ batch_processor.log
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: é¦–æ¬¡è¿è¡Œå¾ˆæ…¢ï¼Ÿ
**A:** é¦–æ¬¡è¿è¡Œä¼šä» HuggingFace ä¸‹è½½æ¨¡å‹ï¼ˆçº¦10GBï¼‰ï¼Œéœ€è¦ç¨³å®šç½‘ç»œã€‚åç»­è¿è¡Œä¼šä½¿ç”¨ç¼“å­˜ã€‚

### Q2: å¦‚ä½•åŠ é€Ÿå¤„ç†ï¼Ÿ
**A:**
1. ç¡®ä¿ä½¿ç”¨ SSD å­˜å‚¨
2. æé«˜ç½‘ç»œå¸¦å®½ï¼ˆAPIè°ƒç”¨ï¼‰
3. ä½¿ç”¨æ¿€è¿›é…ç½®ï¼ˆè§ä¼˜åŒ–é…ç½®ï¼‰

### Q3: JSONéªŒè¯å¤±è´¥ï¼Ÿ
**A:**
1. æ£€æŸ¥ `json schema.json` æ–‡ä»¶å­˜åœ¨
2. æŸ¥çœ‹ `logs/batch_processor.log` è¯¦ç»†é”™è¯¯
3. å¯ç”¨è‡ªåŠ¨ä¿®å¤ï¼š`config.validation.AUTO_FIX_SCHEMA_ERRORS = True`

### Q4: å¦‚ä½•æ‰¹é‡å¤„ç†å¤šä¸ªPDFï¼Ÿ
**A:**
```bash
# å°†æ‰€æœ‰PDFæ”¾å…¥ input_pdfs/
cp /path/to/pdfs/*.pdf input_pdfs/

# è¿è¡Œæ‰¹é‡å¤„ç†
python run_batch_processor.py -y

# åå°è¿è¡Œ
nohup python run_batch_processor.py -y > processing.log 2>&1 &
```

### Q5: å¦‚ä½•æŸ¥çœ‹å¤„ç†è¿›åº¦ï¼Ÿ
**A:**
```bash
# å®æ—¶æ—¥å¿—
tail -f logs/batch_processor.log

# ç»Ÿè®¡å·²å¤„ç†æ–‡ä»¶
ls output_report/ | wc -l

# æŸ¥çœ‹GPUä½¿ç”¨
nvidia-smi
```

---

## ğŸ“ è¿›é˜¶ä½¿ç”¨

### 1. åå°è¿è¡Œ

```bash
# ä½¿ç”¨ nohup
nohup python run_batch_processor.py > processing.log 2>&1 &

# ä½¿ç”¨ screen
screen -S deepseek-ocr
python run_batch_processor.py
# Ctrl+A, D åˆ†ç¦»ä¼šè¯
# screen -r deepseek-ocr  # é‡æ–°è¿æ¥

# ä½¿ç”¨ tmux
tmux new -s deepseek-ocr
python run_batch_processor.py
# Ctrl+B, D åˆ†ç¦»ä¼šè¯
# tmux attach -t deepseek-ocr  # é‡æ–°è¿æ¥
```

### 2. å®šæ—¶ä»»åŠ¡

```bash
# æ·»åŠ åˆ° crontab
crontab -e

# æ¯å¤©å‡Œæ™¨2ç‚¹å¤„ç†
0 2 * * * cd /path/to/deepseek-ocr-batch && /path/to/conda/envs/deepseek-ocr/bin/python run_batch_processor.py -y >> /path/to/cron.log 2>&1
```

### 3. ç›‘æ§è„šæœ¬

```bash
# åˆ›å»ºç›‘æ§è„šæœ¬
cat > monitor.sh << 'EOF'
#!/bin/bash
while true; do
    clear
    echo "=== GPU Status ==="
    nvidia-smi --query-gpu=utilization.gpu,utilization.memory,memory.used,memory.total --format=csv,noheader
    echo ""
    echo "=== Processing Status ==="
    tail -n 5 logs/batch_processor.log
    echo ""
    echo "=== Output Count ==="
    echo "OCR Results: $(ls output_results/ 2>/dev/null | wc -l)"
    echo "JSON Reports: $(ls output_report/ 2>/dev/null | wc -l)"
    sleep 5
done
EOF

chmod +x monitor.sh
./monitor.sh
```

---

## ğŸ“š æ›´å¤šèµ„æº

- **è¯¦ç»†æ–‡æ¡£:** `CLAUDE.md`
- **ä¼˜åŒ–è¯´æ˜:** `RTX4090_OPTIMIZATION.md`
- **é¡¹ç›®è¯´æ˜:** `README.md`
- **é…ç½®æ–‡ä»¶:** `config_batch.py`
- **JSON Schema:** `json schema.json`

---

## ğŸ†˜ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜æ—¶ï¼Œè¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

```bash
# 1. ç³»ç»Ÿä¿¡æ¯
python test_batch_system.py > system_info.txt

# 2. é”™è¯¯æ—¥å¿—
tail -n 100 logs/batch_processor.log > error_log.txt

# 3. GPUçŠ¶æ€
nvidia-smi > gpu_status.txt

# 4. ç¯å¢ƒä¿¡æ¯
conda list > conda_env.txt
pip list > pip_env.txt
```

---

## âœ¨ å¿«é€Ÿå‘½ä»¤å‚è€ƒ

```bash
# ç¯å¢ƒæ¿€æ´»
conda activate deepseek-ocr

# æµ‹è¯•ç³»ç»Ÿ
python test_batch_system.py

# å¤„ç†PDF
python run_batch_processor.py

# åå°è¿è¡Œ
nohup python run_batch_processor.py -y > processing.log 2>&1 &

# ç›‘æ§GPU
watch -n 1 nvidia-smi

# æŸ¥çœ‹æ—¥å¿—
tail -f logs/batch_processor.log

# æŸ¥çœ‹ç»“æœ
ls -lh output_report/

# éªŒè¯JSON
python -m json.tool output_report/test/test.json

# åœæ­¢å¤„ç†
pkill -f "python.*run_batch_processor.py"
```

---

**ğŸ‰ æ­å–œï¼ä½ å·²ç»æˆåŠŸå¯åŠ¨ DeepSeek OCR æ‰¹é‡å¤„ç†ç³»ç»Ÿï¼**

**æ€§èƒ½æç¤ºï¼š** RTX 4090 48G é…ç½®ä¸‹ï¼Œé¢„è®¡å¤„ç†é€Ÿåº¦æ¯” RTX 3090 24G å¿« **3-4å€**ï¼

**ä¸‹ä¸€æ­¥ï¼š** é˜…è¯» `RTX4090_OPTIMIZATION.md` äº†è§£æ›´å¤šä¼˜åŒ–æŠ€å·§ã€‚
